---
title: "prior_predictive_checks.Rmd"
output: html_document
date: '2025-04-03'
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
# Plot example histograms (e.g., first 4 sims)
library(ggplot2)
library(rstan)
```

#3 predictors for LN, 1 for binom, non-hierarchical, single sim
```{r}

# Set seed for reproducibility
set.seed(9)

# Number of grid cells
N <- 2942  # Adjust as needed

# Simulate predictor values
X1 <- runif(N, 0, 1)  # Proportion of renters (continuous variable)
X2 <- runif(N, 0, 1)  # Proportion of renters (continuous variable)
X3 <- runif(N, 0, 1)  # Proportion of renters (continuous variable)
P1 <- runif(N, 0, 1)  # Pavement proportion (continuous variable)

# Sample parameters from priors
mu <- rnorm(1, -6, 4)          # Prior for raw mean food waste
beta1 <- rnorm(1, 0,4 )        # Prior for effect of X1
beta2 <- rnorm(1, 0,4 )        # Prior for effect of X1
beta3 <- rnorm(1, 0,4 )        # Prior for effect of X1
sigma <- abs(rnorm(1, 0, 1))  # Ensure positive sigma

gamma <- rnorm(1, 0, 1)      # Prior for zero-inflation intercept
delta1 <- rnorm(1, 0, 1)      # Prior for effect of P1 on zero-inflation

# Compute transformed parameters
mean_raw <- exp(mu + beta1 * X1 + beta2*X2 + beta3*X3)  # Raw mean values (no log transformation)
pi <- plogis(gamma + delta1 * P1)  # Probability of zero-inflation (logistic link)

# Generate zero-inflated lognormal food waste scores
fw_score_weighted <- numeric(N)
for (n in 1:N) {
  if (runif(1) < pi[n]) {
    fw_score_weighted[n] <- 0  # Zero food waste with probability pi
  } else {
    fw_score_weighted[n] <- rlnorm(1, log(mean_raw[n]), sigma)  # Raw scale
  }
}

fw_scores_no0 <- fw_score_weighted[fw_score_weighted>0]

# Plot histogram of generated food waste scores (raw scale)
ggplot(data.frame(fw_score_weighted), aes(x = fw_score_weighted)) +
  geom_histogram(bins = 100, fill = "blue", alpha = 0.5) +
  theme_minimal() +
  labs(title = "Simulated Food Waste Scores (Raw Scale)",
       x = "Food Waste Score", y = "Count")

# Plot histogram of generated food waste scores (raw scale)
ggplot(data.frame(fw_scores_no0), aes(x = fw_scores_no0)) +
  geom_histogram(bins = 100, fill = "blue", alpha = 0.5) +
  theme_minimal() +
  labs(title = "Simulated Food Waste Scores (Raw Scale)",
       x = "Food Waste Score", y = "Count")

```
#3 predictors for LN, 1 for binom, non-hierarchical
```{r}
set.seed(150)

# Number of grid cells
N <- 2942

# Number of simulations
n_sim <- 20

# Store all simulations
all_sim_data <- list()

# Loop over multiple draws from prior
for (i in 1:n_sim) {
  # Simulate predictor values
  X1 <- runif(N, 0, 1)
  X2 <- runif(N, 0, 1)  # Proportion of renters (continuous variable)
  X3 <- runif(N, 0, 1)  # Proportion of renters (continuous variable)
  P1 <- runif(N, 0, 1)

  # Sample parameters from priors
  mu <- rnorm(1, -4.5, 3)
  beta1 <- rnorm(1, 0,4 )        # Prior for effect of X1
  beta2 <- rnorm(1, 0,4 )        # Prior for effect of X1
  beta3 <- rnorm(1, 0,4 )        # Prior for effect of X1
  sigma <- abs(rnorm(1, 0, 1))

 # gamma <- rbeta(1, 12, 3) ## beta is unstable..
  gamma <- rnorm(1, 0.5, 0.5)
  delta1 <- rnorm(1, 0.5, 1)

  # Compute transformed parameters
  mean_raw <- exp(mu + beta1 * X1 + beta2 * X2 + beta3 * X3)
  pi <- plogis(gamma + delta1 * P1)

  # Simulate data
  fw_score_weighted <- numeric(N)
  for (n in 1:N) {
    if (runif(1) < pi[n]) {
      fw_score_weighted[n] <- 0
    } else {
      fw_score_weighted[n] <- rlnorm(1, log(mean_raw[n]), sigma)
    }
  }

  all_sim_data[[i]] <- data.frame(
    sim_id = i,
    fw_score_weighted = fw_score_weighted,
    non_zero = fw_score_weighted > 0
  )
}

# Combine all simulations
sim_df <- bind_rows(all_sim_data)

ggplot(filter(sim_df, sim_id <= 10), aes(x = fw_score_weighted)) +
  geom_histogram(bins = 100, fill = "darkblue", alpha = 0.6) +
  facet_wrap(~ sim_id, scales = "free_x") +
  theme_minimal() +
  labs(title = "Prior Predictive Simulations: Food Waste Scores",
       x = "Food Waste Score", y = "Count")

# Optionally: plot proportion of zeros per simulation
sim_summary <- sim_df %>%
  group_by(sim_id) %>%
  summarise(pct_zero = mean(fw_score_weighted == 0))

ggplot(sim_summary, aes(x = sim_id, y = pct_zero)) +
  geom_col(fill = "firebrick") +
  theme_minimal() +
  labs(title = "Proportion of Zeros by Simulation",
       x = "Simulation ID", y = "Proportion Zero")

```
#hierarchical data

```{r}
# Simulate data with hierarchical structure (site-level intercepts)
# Matches Stan model with 13 sites and varying intercepts

set.seed(150)
N <- 2942
J <- 13
n_sim <- 20

# Create site IDs
site_id <- sample(1:J, size = N, replace = TRUE)

# Store simulation outputs
all_sims <- list()

for (i in 1:n_sim) {
  # Simulate predictors
  X1 <- runif(N, 0, 1)
  X2 <- runif(N, 0, 1)
  X3 <- runif(N, 0, 1)
  P1 <- runif(N, 0, 1)

  # Hierarchical priors
  mu0 <- rnorm(1, -4.5, 3)
  tau_mu <- abs(rnorm(1, 0, 1))
  mu_raw <- rnorm(J, 0, 1)
  mu_site <- mu0 + tau_mu * mu_raw

  beta1 <- rnorm(1, 0, 1)
  beta2 <- rnorm(1, 0, 1)
  beta3 <- rnorm(1, 0, 1)
  sigma <- abs(rnorm(1, 0, 1))

  gamma <- rnorm(1, 0.75, 0.25)
  delta1 <- rnorm(1, 0, 1)

  # Compute linear predictors
  log_mean <- mu_site[site_id] + beta1 * X1 + beta2 * X2 + beta3 * X3
  pi <- plogis(gamma + delta1 * P1)
  mean_raw <- exp(log_mean)

  # Simulate zero-inflated lognormal response
  fw_score_weighted <- numeric(N)
  for (n in 1:N) {
    if (runif(1) < pi[n]) {
      fw_score_weighted[n] <- 0
    } else {
      fw_score_weighted[n] <- rlnorm(1, log(mean_raw[n]), sigma)
    }
  }

  all_sims[[i]] <- tibble(
    sim_id = i,
    fw_score_weighted,
    site = site_id,
    zero = fw_score_weighted == 0
  )
}

# Combine all
sim_df <- bind_rows(all_sims)

# Plot: Histograms of food waste by simulation
ggplot(filter(sim_df, sim_id <= 8), aes(x = fw_score_weighted)) +
  geom_histogram(bins = 100, fill = "steelblue", alpha = 0.6) +
  facet_wrap(~ sim_id, scales = "free_x") +
  theme_minimal() +
  labs(title = "Prior Predictive Simulations: Food Waste Scores",
       x = "Food Waste Score", y = "Count")

# Plot: Proportion of Zeros by simulation
sim_df %>%
  group_by(sim_id) %>%
  summarise(p_zero = mean(zero)) %>%
  ggplot(aes(x = sim_id, y = p_zero)) +
  geom_col(fill = "firebrick") +
  theme_minimal() +
  labs(title = "Proportion of Zeros by Simulation",
       x = "Simulation ID", y = "Proportion Zero")

# Optional: Variation in site-level means (per simulation)
site_means <- sim_df %>%
  group_by(sim_id, site) %>%
  summarise(mean_fw = mean(fw_score_weighted), .groups = "drop")

ggplot(site_means, aes(x = factor(site), y = mean_fw)) +
  geom_boxplot(fill = "darkgreen", alpha = 0.5) +
  facet_wrap(~ sim_id, scales = "free_y") +  # Allow y-axis to vary
  labs(title = "Site-level Mean Food Waste Scores by Simulation",
       x = "Site", y = "Mean Food Waste Score") +
  theme_minimal()


```


#### PRIOR PREDICTIVE CHECKS


```{r}
# Simulate dummy data (same structure, but no outcome)
N <- 3531
J <- 13
site_id <- sample(1:J, N, replace = TRUE)
X1 <- rnorm(N)
X2 <- rnorm(N)
X3 <- rnorm(N)
X4 <- rnorm(N)
P1 <- rnorm(N)
P2 <- rnorm(N)

stan_data <- list(
  N = N,
  J = J,
  site_id = site_id,
  X1 = X1,
  X2 = X2,
  X3 = X3,
  X4 = X4,
  P1 = P1,
  P2 = P2,
  fw_score_weighted = rep(0.0, N)  # Dummy, won't be used
)

fit_prior_checks <- stan(
  file = "priorpredictivechecks_model.stan",  # Save the modified model above
  data = stan_data,
  chains = 4,
  iter = 1000,
  seed = 123
)



```


```{r}
# Extract posterior samples
y_rep <- rstan::extract(fit_prior_checks)$fw_score_pred  # Change "y_rep" based on how you named your predicted values
pi_pred <- rstan::extract(fit_prior_checks)$pi_pred  # Change "y_rep" based on how you named your predicted values
y_obs <- dat_clean$fw_score_weighted  # Replace with actual observed data
pi_obs <- ifelse(dat_grid_final$fw_score_weighted > 0 , 0, 1)  # Convert to binary presence/absence



# Extract samples
prior_samples <- rstan::extract(fit_prior_checks)

# Explore distributions
hist(prior_samples$mu0, breaks = 40, main = "mu0", col = "skyblue")
hist(prior_samples$tau_mu, breaks = 40, main = "tau_mu", col = "salmon")
hist(prior_samples$mu, breaks = 40, main = "mu = mu0 + tau_mu * mu_raw", col = "lightgreen")
hist(prior_samples$sigma, breaks = 40, main = "sigma", col = "lightblue")
hist(prior_samples$beta1, breaks = 40, main = "beta1", col = "yellow")
hist(prior_samples$beta2, breaks = 40, main = "beta2", col = "purple")
hist(prior_samples$gamma, breaks = 40, main = "gamma", col = "pink")
hist(prior_samples$delta1, breaks = 40, main = "delta1", col = "orange")
hist(prior_samples$delta2, breaks = 40, main = "delta2", col = "brown")



ppc_dens_overlay(y_obs, y_rep[1000:1050, ])  # Plot overlay of observed vs simulated densities


# Plot overlay of observed vs simulated densities with x-axis range 0 to 4
ppc_dens_overlay(y_obs, y_rep[1000:1050, ]) +
  xlim(0.001,1) +
  labs(title = "Posterior Predictive Check (X Range: 0 to 1)",
       x = "Food Waste Score",
       y = "Density") +
  theme_minimal()


# Convert posterior predictive samples to a long format
pi_pred_df <- as.data.frame(pi_pred)
pi_pred_long <- pi_pred_df %>%
  pivot_longer(cols = everything(), names_to = "Iteration", values_to = "pi_pred")
# Calculate the mean of pi_obs
mean_pi_obs <- mean(pi_obs, na.rm = TRUE)

# Create the plot
ggplot(pi_pred_long, aes(x = pi_pred)) +
  geom_histogram(binwidth = 0.05, fill = "lightblue", color = "black", alpha = 0.7) +
  geom_vline(xintercept = mean_pi_obs, color = "red", linetype = "dashed", linewidth = 1) +  # Add red vertical line
  labs(title = "Posterior Predictive Check for pi",
       x = "Predicted pi",
       y = "Frequency") +
  theme_minimal()


```

```{r}
# Function to compute proportion of zeros
prop_zeros <- function(y) mean(y == 0)

# Compute proportion of zeros for each posterior predictive draw
prop_zeros_sim <- apply(y_rep, 1, prop_zeros)

# Compute proportion of zeros in observed data
prop_zeros_obs <- mean(y_obs == 0)

# Plot
ppc_stat(y = y_obs, yrep = y_rep, stat = "prop_zeros") +
  geom_vline(xintercept = prop_zeros_obs, color = "red", linetype = "dashed", size = 1) +
  labs(title = "Posterior Predictive Check: Proportion of Zeros",
       x = "Proportion Zero", y = "Frequency") +
  theme_minimal()

```
```{r}
summary(y_rep[1:7062000])
summary(dat_clean$fw_score_weighted)
summary(y_obs)
summary(pi_obs)
summary(pi_pred[1:7062000])
```
```{r}
mean_observed <- mean(y_obs)
mean_simulated <- apply(y_rep, 1, mean)
hist(mean_simulated, probability = TRUE, main = "Posterior Predictive Means",breaks = 100)
abline(v = mean_observed, col = "blue", lwd = 2)
```


```{r}
# Convert y_rep to data frame and add draw number
y_rep_df <- as.data.frame(y_rep) %>%
  mutate(draw = row_number())

site_id <- dat_scaled$site_id  # Or however it's stored in your data

site_legend <- data.frame(
  site = dat_scaled$site,
  site_id = dat_scaled$site_id
)

site_legend_unique <- unique(site_legend)
site_legend_unique <- site_legend_unique[order(site_legend_unique$site_id), ]


# Pivot to long format
y_rep_long <- y_rep_df %>%
  tidyr::pivot_longer(-draw, names_to = "obs", values_to = "y") %>%
  mutate(obs = as.integer(str_remove(obs, "^V")),
         site = site_id[obs])

site_means <- y_rep_long %>%
  group_by(draw, site) %>%
  summarise(mean_y = mean(y), .groups = "drop")

ggplot(site_means, aes(x = factor(site), y = mean_y)) +
  geom_boxplot(fill = "skyblue", alpha = 0.7) +
  labs(title = "Posterior Predictive Means per Site",
       x = "Site",
       y = "Mean Predicted Food Waste") +
  theme_minimal()



# Join ordered factor levels to site_means
site_means <- site_means %>%
  mutate(site = factor(site, levels = site_order$site))

# Make sure site_legend_unique has the correct order
site_legend_unique <- site_legend_unique %>%
  mutate(site_id = as.integer(site_id)) %>%
  arrange(match(site_id, levels(site_means$site)))



# Plot with violin and mean line
ggplot(site_means, aes(x = site, y = mean_y)) +
  geom_violin(fill = "skyblue", alpha = 0.7, scale = "width", trim = FALSE) +
  stat_summary(fun = mean, geom = "point", shape = 23, size = 3, fill = "red") +
  scale_x_discrete(labels = site_legend_unique$site) +
  labs(
    title = "Posterior Predictive Means per Site (Ordered by Mean)",
    x = "Site",
    y = "Mean Predicted Food Waste"
  ) +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))


# Plot with violin and mean line
ggplot(site_means, aes(x = site, y = log(mean_y))) +
  geom_violin(fill = "skyblue", alpha = 0.7, scale = "width", trim = FALSE) +
  stat_summary(fun = mean, geom = "point", shape = 23, size = 3, fill = "red") +
  scale_x_discrete(labels = site_legend_unique$site) +
  labs(
    title = "Posterior Predictive Means per Site (Ordered by Mean)",
    x = "Site",
    y = "Mean Predicted Food Waste"
  ) +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

```

